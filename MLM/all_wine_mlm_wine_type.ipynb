{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "red_wine = pd.read_csv(\"wine+quality\\winequality-red.csv\", sep= ';', delimiter=None) \n",
    "white_wine = pd.read_csv(\"wine+quality\\winequality-white.csv\", sep= ';', delimiter=None) \n",
    "\n",
    "#make a copy\n",
    "rw = red_wine\n",
    "ww = white_wine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions \n",
    "do we have to remove all spaces from column names for the ML modell to work? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do \n",
    "- remove duplicates \n",
    "- unify column names - remove spaces - example is in the movie data set book \n",
    "- check for null values \n",
    "\n",
    "- add column to each data set identifying red or white label - call it wine type \n",
    "    for loop? to fill the column \n",
    "- change data type to numerical?? \n",
    "- combine data sets \n",
    "\n",
    "Later \n",
    "- create new low medium high classification \n",
    "  low 1-4, medium 5-6, high 7-10 \n",
    "- justification: our main focus is on what produces good quality wine. good is defined as above average. the average for red was 5.5 and the average for white was 5.9 \n",
    "- so 5-6 is of medium quality because it represents the mean. anything below that is of low quality, and anything above that is considered high quality in this evalutation \n",
    "- also refereing to using the model for future data, 5 is the mediam of my quality range and extending that range upward will only increase the quality \n",
    "\n",
    "\n",
    "- maybe i could do a 5 Star Rating, make 5 groups, each with 2 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all duplicates \n",
    "rw.drop_duplicates(inplace=True)\n",
    "ww.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unify column names \n",
    "rw.rename(columns = {'fixed acidity':'fixed_acidity','volatile acidity':'volatile_acidity','citric acid':'citric_acid','residual sugar':'residual_sugar','free sulfur dioxide':'free_sulfur_dioxide', 'total sulfur dioxide':'total_sulfur_dioxide'}, inplace=True)\n",
    "ww.rename(columns = {'fixed acidity':'fixed_acidity','volatile acidity':'volatile_acidity','citric acid':'citric_acid','residual sugar':'residual_sugar','free sulfur dioxide':'free_sulfur_dioxide', 'total sulfur dioxide':'total_sulfur_dioxide'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column \n",
    "rw.insert(12, \"colour\", 'red')\n",
    "ww.insert(12, \"colour\", 'white')\n",
    "#could also do rw[\"colour\"] = \"red\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data sets \n",
    "data = [rw, ww] #its placing data ets on top of each other = ignor_index \n",
    "df_clean = pd.concat(data, ignore_index=True)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check colour column, data type \n",
    "df_clean[\"colour\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use One-Hot Encoder to convert the colour column from categorical str object to readable numbers \n",
    "#automatic assigning is 1 \n",
    "df_clean[\"colour\"] = (df_clean[\"colour\"] == \"red\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head looks weird so using value_counts to check count and dtype \n",
    "df_clean.colour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm1 = df_clean.copy()\n",
    "mlm1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Model\n",
    "- split the data \n",
    "- feature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data using the train_test_split function \n",
    "\n",
    "#X=mlm1.data\n",
    "#y=mlm1.target\n",
    "\n",
    "#y=x.colour\n",
    "#x.drop(['colour'], axis=1)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using numpy np.split\n",
    "#to split by 3 instead of 2 \n",
    "train, valid, test = np.split(mlm1.sample(frac=1), [int(0.6*len(mlm1)), int(0.8*len(mlm1))])\n",
    "#.sample will shuffle my data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the scale of all my numbers \n",
    "def scale_dataset(mlm1, oversample=False):\n",
    "    X = mlm1[mlm1.columns[:-1]].values #calling all columns until the last one \n",
    "    y = mlm1[mlm1.columns[-1]].values #calling only the last column \n",
    "\n",
    "    scaler = StandardScaler() # check rules here for group splitting \n",
    "    X = scaler.fit_transform(X) \n",
    "\n",
    "    if oversample: \n",
    "        ros = RandomOverSampler()  \n",
    "        X, y = ros.fit_resample(X, y)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "    # y is only 2D, so call numpy reshape to make it  3Dimensional Item \n",
    "    # because y is only 1 column\n",
    "\n",
    "    return data, X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train[train[\"colour\"] ==1 ])) # colour = red \n",
    "print(len(train[train[\"colour\"] ==0 ])) # colour = white \n",
    "# you can import oversampling from imblearn to increase to lower sample to make the samples more even "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valid[valid[\"colour\"] ==1 ])) \n",
    "print(len(valid[valid[\"colour\"] ==0 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data set using oversampling \n",
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "valid, X_valid, y_valid = scale_dataset(valid, oversample=False)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)\n",
    "\n",
    "#Question: how do i know if the groups were evenly distributed before i \"equalized\" them. what if there were only 2 reds in the train one for ex. have those 2 just been multiplied by 100, i dont quite get it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#red and white in train sample should now be the same number \n",
    "len(y_train)\n",
    "sum(y_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_train == 0)\n",
    "# and they are :) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN - k-nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred should be the same y_test \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check classification report \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy on f1-score = 99% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a confusion matrix  \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#google explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
